{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom zipfile import ZipFile\n\nzip_file = ZipFile('../input/the-winton-stock-market-challenge/train.csv.zip')\ndf = pd.read_csv(zip_file.open('train.csv'))\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-03T04:00:25.027571Z","iopub.execute_input":"2022-01-03T04:00:25.027905Z","iopub.status.idle":"2022-01-03T04:00:28.717271Z","shell.execute_reply.started":"2022-01-03T04:00:25.027876Z","shell.execute_reply":"2022-01-03T04:00:28.714142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_file = ZipFile('../input/the-winton-stock-market-challenge/test_2.csv.zip')\nnew_df = pd.read_csv(zip_file.open('test_2.csv'))\nnew_df.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-01-03T04:00:28.718412Z","iopub.status.idle":"2022-01-03T04:00:28.718802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (15, 5))\ndf_na = (df.isnull().sum() / len(df))\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending = False)[: 30]\nax.bar(range(df_na.size), df_na, width = 0.5)\nplt.xticks(range(df_na.size), df_na.index, rotation = 30)\nplt.ylim([0, 1])\nplt.title('Top 30 features with the most NaN values')\nplt.ylabel('Rate of NaN values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.719922Z","iopub.status.idle":"2022-01-03T04:00:28.720679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret = df.loc[:, 'Ret_2':'Ret_120'].sum(1)\nnew_ret = new_df.loc[:, 'Ret_2':'Ret_120'].sum(1)\n\nX = np.hstack((df.loc[:, 'Feature_1':'Ret_MinusOne'].values, ret.values[:, np.newaxis]))\nts = df.loc[:, 'Ret_2':'Ret_120'].values\ny = df.loc[:, 'Ret_PlusOne':'Ret_PlusTwo'].values\ny_ts = df.loc[:, 'Ret_121':'Ret_180'].values\n\nnew_X = np.hstack((new_df.loc[:, 'Feature_1':'Ret_MinusOne'].values, new_ret.values[:, np.newaxis]))\nnew_ts = new_df.loc[:, 'Ret_2':'Ret_120'].values","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.722925Z","iopub.status.idle":"2022-01-03T04:00:28.723756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimr = SimpleImputer(strategy = 'mean')\nX = imr.fit_transform(X)\nnew_X = imr.transform(new_X)\n\nts = imr.fit_transform(ts)\nnew_ts = imr.transform(new_ts)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.724955Z","iopub.status.idle":"2022-01-03T04:00:28.725789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.plotting import heatmap\n\ncm = np.corrcoef(np.hstack([X, y]).T)\ncols = list(df.columns[1:28]) + ['Ret', 'Ret_PlusOne', 'Ret_PlusTwo']\nhm = heatmap(cm, row_names = cols, column_names = cols, figsize = (20, 20))\nplt.title('correlations between features', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.729016Z","iopub.status.idle":"2022-01-03T04:00:28.729836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X[:30000, :]\nX_val = X[30000:35000, :]\nX_test = X[35000:, :]\ny_train = y[:30000, :]\ny_val = y[30000:35000, :]\ny_test = y[35000:, :]\nX_train_val = X[:35000, :]\ny_train_val = y[:35000, :]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.733068Z","iopub.status.idle":"2022-01-03T04:00:28.733881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1_train = y_train[:, 0]\ny2_train = y_train[:, 1]\ny1_val = y_val[:, 0]\ny2_val = y_val[:, 1]\ny1_test = y_test[:, 0]\ny2_test = y_test[:, 1]\ny1_train_val = y_train_val[:, 0]\ny2_train_val = y_train_val[:, 1]\ny1 = y[:, 0]\ny2 = y[:, 1]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.735074Z","iopub.status.idle":"2022-01-03T04:00:28.735883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\ndtrain = xgb.DMatrix(X_train, label = y1_train)\n\nparam = { 'verbosity': 0,\n          'objective': 'reg:pseudohubererror',\n          'eval_metric': 'mae',\n          'subsample': 0.8,\n          'colsample_bytree': 0.8,\n          'tree_method': 'gpu_hist',\n          'eta': 0.1,\n          'max_depth': 3,\n          'gamma': 0,\n          'min_child_weight': 1 }\n\nbst = xgb.cv(param, dtrain, nfold = 5, num_boost_round = 1000, early_stopping_rounds = 50)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.737113Z","iopub.status.idle":"2022-01-03T04:00:28.737995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_med = xgb.train(param, dtrain, num_boost_round = bst.shape[0])\n\nfig, ax = plt.subplots(figsize = (6, 8))\nxgb.plot_importance(xgb_med, ax = ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.741173Z","iopub.status.idle":"2022-01-03T04:00:28.741969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select = [1, 5, 6, 13, 14, 18, 22, 25, 26, 27]\n\nX_train = X[:30000, select]\nX_val = X[30000:35000, select]\nX_test = X[35000:, select]\nX_train_val = X[:35000, select]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.743183Z","iopub.status.idle":"2022-01-03T04:00:28.744008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n\ndef mysearch(X_train, y_train, X_val, y_val, param, param1, param2 = None, estimator = XGBRegressor, score = mean_absolute_error):\n    best_score = 10000000.\n    best_param = { **param }\n    para = { **param }\n    key1 = list(param1.keys())[0]\n    if param2 is not None:\n        key2 = list(param2.keys())[0]\n        for parama in param1[key1]:\n            for paramb in param2[key2]:\n                para[key1] = parama\n                para[key2] = paramb\n                est = estimator(**para)\n                est.fit(X_train, y_train)\n                y_pred = est.predict(X_val)\n                current_score = score(y_pred, y_val)\n                print('The current score: ', current_score)\n                print('The current parameter: {} = {}, {} = {}'.format(key1, parama, key2, paramb))\n                if (current_score < best_score):\n                    best_score = current_score\n                    best_param[key1] = parama\n                    best_param[key2] = paramb\n        print('The best score: ', best_score)\n        print('The best parameter: {} = {}, {} = {}'.format(key1, best_param[key1], key2, best_param[key2]))\n    else:\n        for parama in param1[key1]:\n            para[key1] = parama\n            est = estimator(**para)\n            est.fit(X_train, y_train)\n            y_pred = est.predict(X_val)\n            current_score = score(y_pred, y_val)\n            print('The current score: ', current_score)\n            print('The current parameter: {} = {}'.format(key1, parama))\n            if (current_score < best_score):\n                best_score = current_score\n                best_param[key1] = parama\n        print('The best score: ', best_score)\n        print('The best parameter: {} = {}'.format(key1, best_param[key1]))\n    return best_score, best_param","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.745251Z","iopub.status.idle":"2022-01-03T04:00:28.746056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {'learning_rate': 0.1,\n         'verbosity': 0,\n         'objective': 'reg:pseudohubererror',\n         'tree_method': 'gpu_hist',\n         'n_estimators': 100,\n         'n_jobs': -1,\n         'gamma': 0,\n         'subsample': 0.8,\n         'colsample_bytree': 0.8,\n         'alpha': 0}\nparam1 = { 'max_depth': [1, 3] }\nparam2 = { 'min_child_weight': [1, 3] }\nscore, bst_param = mysearch(X_train, y1_train, X_val, y1_val, param, param1, param2)\nprint('The best score is:', score)\nprint('The best parameter is:', bst_param)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.747263Z","iopub.status.idle":"2022-01-03T04:00:28.748083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_xgbr = XGBRegressor( objective = 'reg:pseudohubererror',\n                          tree_method = 'gpu_hist',\n                          max_depth = 5,\n                          min_child_weight = 3,\n                          gamma = 0,\n                          subsample = 0.9,\n                          colsample_bytree = 0.9,\n                          alpha = 0,\n                          learning_rate = 0.01,\n                          n_estimators = 700)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.749282Z","iopub.status.idle":"2022-01-03T04:00:28.750102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_xgbr.fit(X_train_val, y1_train_val)\ny1_test_pred = best_xgbr.predict(X_test)\n\nbest_xgbr.fit(X_train_val, y2_train_val)\ny2_test_pred = best_xgbr.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.751319Z","iopub.status.idle":"2022-01-03T04:00:28.752136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nbenchmark = [np.abs(y1_test).mean(), np.abs(y2_test).mean()]\nfitted = [mean_absolute_error(y1_test_pred, y_test[:, 0]), mean_absolute_error(y2_test_pred, y_test[:, 1])]\n\nindex = np.arange(2)\nbar_width = 0.35\nplt.bar(index, benchmark, bar_width, label = 'All-zero prediction')\nplt.bar(index + bar_width, fitted, bar_width, label = 'XGBoost regressor')\nplt.xticks(index + bar_width / 2, ['Ret_PlusOne', 'Ret_PlusTwo'])\nplt.title('XGBoost regressor VS all-zero prediction')\nplt.xlabel('Stock returns in the two following days')\nplt.ylabel('MAE on pridiction')\nplt.ylim([0, 0.02])\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.753378Z","iopub.status.idle":"2022-01-03T04:00:28.754174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_xgbr.fit(X[:, select], y[:, 0])\ny1_new_pred = best_xgbr.predict(new_X[:, select])\n\nbest_xgbr.fit(X[:, select], y[:, 1])\ny2_new_pred = best_xgbr.predict(new_X[:, select])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.755462Z","iopub.status.idle":"2022-01-03T04:00:28.756341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1_new_pred = 0.05 * y1_new_pred + 0.95 * np.median(y[:, 0])\ny2_new_pred = 0.05 * y2_new_pred + 0.95 * np.median(y[:, 1])\n\nts_new_pred = np.zeros((new_X.shape[0], 60))\n\nzip_file = ZipFile('../input/the-winton-stock-market-challenge/sample_submission_2.csv.zip')\nsub = pd.read_csv(zip_file.open('sample_submission_2.csv'))\nsub['Predicted'] = np.hstack([ts_new_pred, y1_new_pred[:, np.newaxis], np.median(y[:, 1])* np.ones((new_X.shape[0], 1))]).flatten()\nsub.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:00:28.757584Z","iopub.status.idle":"2022-01-03T04:00:28.758394Z"},"trusted":true},"execution_count":null,"outputs":[]}]}