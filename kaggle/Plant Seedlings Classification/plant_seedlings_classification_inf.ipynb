{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Import Library ##\nimport warnings \nwarnings.filterwarnings('ignore')\nimport os\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport cv2\nfrom PIL import Image\n\n# torch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\n# image processing\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, Flip,\n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:29.950640Z","iopub.execute_input":"2022-02-08T07:08:29.951179Z","iopub.status.idle":"2022-02-08T07:08:32.927064Z","shell.execute_reply.started":"2022-02-08T07:08:29.951065Z","shell.execute_reply":"2022-02-08T07:08:32.926241Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install timm\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:32.928431Z","iopub.execute_input":"2022-02-08T07:08:32.928761Z","iopub.status.idle":"2022-02-08T07:08:43.567886Z","shell.execute_reply.started":"2022-02-08T07:08:32.928706Z","shell.execute_reply":"2022-02-08T07:08:43.566935Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Configuration ##\nclass CFG:\n    num_workers=4\n    size=324 \n    size_swin = 224\n    batch_size=32\n    num_classes= 12\n    trn_fold=[0, 1, 2, 3]\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:43.570373Z","iopub.execute_input":"2022-02-08T07:08:43.570742Z","iopub.status.idle":"2022-02-08T07:08:43.617739Z","shell.execute_reply.started":"2022-02-08T07:08:43.570686Z","shell.execute_reply":"2022-02-08T07:08:43.616801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## Directory path ##\nckpt_path = '../input/d/minjuro/plant-seedlings-cls-checkpoint/checkpoint_swin/'\nTEST_PATH = '../input/plant-seedlings-classification/test'","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:43.619582Z","iopub.execute_input":"2022-02-08T07:08:43.620099Z","iopub.status.idle":"2022-02-08T07:08:43.625815Z","shell.execute_reply.started":"2022-02-08T07:08:43.620059Z","shell.execute_reply":"2022-02-08T07:08:43.624981Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"convert_classes = {0: 'Black-grass',\n         1: 'Charlock',\n         2: 'Cleavers',\n         3: 'Common Chickweed',\n         4: 'Common wheat',\n         5: 'Fat Hen',\n         6: 'Loose Silky-bent',\n         7: 'Maize',\n         8: 'Scentless Mayweed',\n         9: 'Shepherds Purse',\n         10: 'Small-flowered Cranesbill',\n         11: 'Sugar beet'}","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:43.627068Z","iopub.execute_input":"2022-02-08T07:08:43.627476Z","iopub.status.idle":"2022-02-08T07:08:43.634885Z","shell.execute_reply.started":"2022-02-08T07:08:43.627438Z","shell.execute_reply":"2022-02-08T07:08:43.634183Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## load test dataset ##\ntest = pd.DataFrame(columns=['file'])\npathToTestData='../input/plant-seedlings-classification/test'\n\nfor dirname, _, filenames in os.walk(pathToTestData):\n    for filename in filenames:\n        file = filename\n        test = test.append({'file': file}, ignore_index = True)\ntest.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:43.636203Z","iopub.execute_input":"2022-02-08T07:08:43.636579Z","iopub.status.idle":"2022-02-08T07:08:45.056472Z","shell.execute_reply.started":"2022-02-08T07:08:43.636503Z","shell.execute_reply":"2022-02-08T07:08:45.055579Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.057640Z","iopub.execute_input":"2022-02-08T07:08:45.058006Z","iopub.status.idle":"2022-02-08T07:08:45.064367Z","shell.execute_reply.started":"2022-02-08T07:08:45.057973Z","shell.execute_reply":"2022-02-08T07:08:45.063576Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"## Transform ##\ndef get_transforms(*, size, data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(size, size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(size, size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.065555Z","iopub.execute_input":"2022-02-08T07:08:45.066062Z","iopub.status.idle":"2022-02-08T07:08:45.075974Z","shell.execute_reply.started":"2022-02-08T07:08:45.066025Z","shell.execute_reply":"2022-02-08T07:08:45.075216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## Model ##\nclass customModel(nn.Module):\n    def __init__(self, model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        self.fc_layer = nn.Linear(1000,CFG.num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        out = self.fc_layer(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.078736Z","iopub.execute_input":"2022-02-08T07:08:45.079275Z","iopub.status.idle":"2022-02-08T07:08:45.086327Z","shell.execute_reply.started":"2022-02-08T07:08:45.079212Z","shell.execute_reply":"2022-02-08T07:08:45.085569Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"## inf function ##\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state['model'])\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.087609Z","iopub.execute_input":"2022-02-08T07:08:45.088182Z","iopub.status.idle":"2022-02-08T07:08:45.096505Z","shell.execute_reply.started":"2022-02-08T07:08:45.088141Z","shell.execute_reply":"2022-02-08T07:08:45.095674Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def main(ckpt_path, mod_name):\n    model = customModel(mod_name, pretrained=False)\n    states = [torch.load(ckpt_path+f'{mod_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n    \n    if mod_name == \"swin_base_patch4_window7_224\":\n        test_dataset = TestDataset(test, transform=get_transforms(size = CFG.size_swin, data='valid'))\n    else:\n        test_dataset = TestDataset(test, transform=get_transforms(size = CFG.size, data='valid'))\n\n    \n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True)\n    predictions = inference(model, states, test_loader, device)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.097895Z","iopub.execute_input":"2022-02-08T07:08:45.098290Z","iopub.status.idle":"2022-02-08T07:08:45.109006Z","shell.execute_reply.started":"2022-02-08T07:08:45.098254Z","shell.execute_reply":"2022-02-08T07:08:45.108118Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"result = main(ckpt_path, \"swin_base_patch4_window7_224\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:08:45.110592Z","iopub.execute_input":"2022-02-08T07:08:45.110939Z","iopub.status.idle":"2022-02-08T07:09:32.465540Z","shell.execute_reply.started":"2022-02-08T07:08:45.110904Z","shell.execute_reply":"2022-02-08T07:09:32.464604Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## Submission File ##\ntest['species'] = result.argmax(1)\nfor i in range(len(test)):\n    test.species[i] = convert_classes[test.species[i]]\ntest.to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:09:32.467272Z","iopub.execute_input":"2022-02-08T07:09:32.467631Z","iopub.status.idle":"2022-02-08T07:09:32.874147Z","shell.execute_reply.started":"2022-02-08T07:09:32.467592Z","shell.execute_reply":"2022-02-08T07:09:32.873239Z"},"trusted":true},"execution_count":13,"outputs":[]}]}