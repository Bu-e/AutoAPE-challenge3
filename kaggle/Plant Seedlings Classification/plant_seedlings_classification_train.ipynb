{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Import Library ##\nimport warnings \nwarnings.filterwarnings('ignore')\nimport os\n\nimport math\nimport time\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\n\nimport cv2\n\n# torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\n# image processing\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, Flip, \n    IAAAdditiveGaussianNoise, Transpose, CenterCrop \n    )\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:48:44.952430Z","iopub.execute_input":"2022-02-08T06:48:44.952978Z","iopub.status.idle":"2022-02-08T06:48:48.696377Z","shell.execute_reply.started":"2022-02-08T06:48:44.952855Z","shell.execute_reply":"2022-02-08T06:48:48.695184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install timm\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:48:48.699318Z","iopub.execute_input":"2022-02-08T06:48:48.700169Z","iopub.status.idle":"2022-02-08T06:49:00.706291Z","shell.execute_reply.started":"2022-02-08T06:48:48.700125Z","shell.execute_reply":"2022-02-08T06:49:00.704981Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Config ##\nclass CFG:\n    print_freq=100\n    num_workers=4\n    model_name='swin_base_patch4_window7_224'\n    size = 224\n    scheduler='CosineAnnealingLR'\n    epochs= 5\n    T_max=10 \n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    weight_decay=1e-6\n    max_grad_norm=1000\n    seed=42\n    num_classes= 12\n    target_col='species'\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:00.709464Z","iopub.execute_input":"2022-02-08T06:49:00.709921Z","iopub.status.idle":"2022-02-08T06:49:00.772448Z","shell.execute_reply.started":"2022-02-08T06:49:00.709871Z","shell.execute_reply":"2022-02-08T06:49:00.771134Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:00.774961Z","iopub.execute_input":"2022-02-08T06:49:00.775447Z","iopub.status.idle":"2022-02-08T06:49:00.788132Z","shell.execute_reply.started":"2022-02-08T06:49:00.775402Z","shell.execute_reply":"2022-02-08T06:49:00.786982Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## Dataset class ##\nclasses = {'Black-grass': 0,\n         'Charlock': 1,\n         'Cleavers': 2,\n         'Common Chickweed': 3,\n         'Common wheat': 4,\n         'Fat Hen': 5,\n         'Loose Silky-bent': 6,\n         'Maize': 7,\n         'Scentless Mayweed': 8,\n         'Shepherds Purse': 9,\n         'Small-flowered Cranesbill': 10,\n         'Sugar beet': 11}","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:00.789922Z","iopub.execute_input":"2022-02-08T06:49:00.790813Z","iopub.status.idle":"2022-02-08T06:49:00.798235Z","shell.execute_reply.started":"2022-02-08T06:49:00.790767Z","shell.execute_reply":"2022-02-08T06:49:00.796818Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## Directory path ##\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:00.801703Z","iopub.execute_input":"2022-02-08T06:49:00.802005Z","iopub.status.idle":"2022-02-08T06:49:00.812769Z","shell.execute_reply.started":"2022-02-08T06:49:00.801976Z","shell.execute_reply":"2022-02-08T06:49:00.811466Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## Load train dataset ##\ntrain = pd.DataFrame(columns=['image_path','species', 'file'])\ntrain.astype({'species': 'int32'})\n\npathToTrainData='../input/plant-seedlings-classification/train'\n\nfor dirname, _, filenames in tqdm(os.walk(pathToTrainData)):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        class_label = dirname.split('/')[-1]\n        class_label = classes[class_label]\n        file = filename\n        train = train.append({'file': file, 'image_path':path , 'species':class_label}, ignore_index = True)\n\ntrain.astype({'species': 'int'}).dtypes\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:00.814839Z","iopub.execute_input":"2022-02-08T06:49:00.815466Z","iopub.status.idle":"2022-02-08T06:49:24.216647Z","shell.execute_reply.started":"2022-02-08T06:49:00.815412Z","shell.execute_reply":"2022-02-08T06:49:24.215268Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"## K-FOLD ##\nfolds = train.copy()\nX, Y = folds['file'], folds[CFG.target_col].astype('int')\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nFold.get_n_splits(X)\n\nfor n, (train_index, val_index) in enumerate(Fold.split(X, Y)):\n    folds.loc[val_index, 'fold'] = int(n)\n\nfolds['species'] = folds['species'].astype('int32')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.218488Z","iopub.execute_input":"2022-02-08T06:49:24.218970Z","iopub.status.idle":"2022-02-08T06:49:24.240041Z","shell.execute_reply.started":"2022-02-08T06:49:24.218910Z","shell.execute_reply":"2022-02-08T06:49:24.238793Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## Dataset ##\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.file_path = df['image_path'].values\n        self.df = df\n        self.file_name = df['file'].values\n        self.labels = df['species'].values\n        self.transform = transform\n        \n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = f'{self.file_path[idx]}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.244140Z","iopub.execute_input":"2022-02-08T06:49:24.244490Z","iopub.status.idle":"2022-02-08T06:49:24.254562Z","shell.execute_reply.started":"2022-02-08T06:49:24.244458Z","shell.execute_reply":"2022-02-08T06:49:24.251480Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"## Transform ##\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(224,224),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.256860Z","iopub.execute_input":"2022-02-08T06:49:24.257369Z","iopub.status.idle":"2022-02-08T06:49:24.268541Z","shell.execute_reply.started":"2022-02-08T06:49:24.257322Z","shell.execute_reply":"2022-02-08T06:49:24.267411Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.270300Z","iopub.execute_input":"2022-02-08T06:49:24.271197Z","iopub.status.idle":"2022-02-08T06:49:24.279254Z","shell.execute_reply.started":"2022-02-08T06:49:24.271147Z","shell.execute_reply":"2022-02-08T06:49:24.278123Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"## Model ##\nclass customModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        self.fc_layer = nn.Linear(1000,CFG.num_classes)\n        \n    def forward(self, x):\n        x = self.model(x)\n        out = self.fc_layer(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.282406Z","iopub.execute_input":"2022-02-08T06:49:24.283139Z","iopub.status.idle":"2022-02-08T06:49:24.293136Z","shell.execute_reply.started":"2022-02-08T06:49:24.283092Z","shell.execute_reply":"2022-02-08T06:49:24.292012Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## util function ##\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef get_score(y_true, y_pred):\n    try:\n        return accuracy_score(y_true, y_pred)\n    except:\n        print(type_of_target(y_true))\n        sys.exit()\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.296596Z","iopub.execute_input":"2022-02-08T06:49:24.297071Z","iopub.status.idle":"2022-02-08T06:49:24.308983Z","shell.execute_reply.started":"2022-02-08T06:49:24.297003Z","shell.execute_reply":"2022-02-08T06:49:24.307601Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Train Function ##\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    \n    model.train()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        \n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                     epoch+1, step, len(train_loader),\n                     loss=losses,\n                   ))\n    return losses.avg","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.311111Z","iopub.execute_input":"2022-02-08T06:49:24.311877Z","iopub.status.idle":"2022-02-08T06:49:24.324074Z","shell.execute_reply.started":"2022-02-08T06:49:24.311829Z","shell.execute_reply":"2022-02-08T06:49:24.322782Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"## Validation Function ##\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    scores = AverageMeter()\n\n    model.eval()\n    preds = []\n\n    for step, (images, labels) in enumerate(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        \n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader),\n                    loss=losses,\n                   ))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.325932Z","iopub.execute_input":"2022-02-08T06:49:24.326473Z","iopub.status.idle":"2022-02-08T06:49:24.338585Z","shell.execute_reply.started":"2022-02-08T06:49:24.326415Z","shell.execute_reply":"2022-02-08T06:49:24.337421Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_loop(folds, fold):\n\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    \n    # Data Loader \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # model & scheduler\n    model = customModel(CFG.model_name, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n    criterion = nn.CrossEntropyLoss()\n\n    # Train\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n    \n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        valid_labels = valid_folds[CFG.target_col].values\n        \n        scheduler.step()\n        \n        score = get_score(valid_labels, preds.argmax(1))\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    \n    \n    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.341553Z","iopub.execute_input":"2022-02-08T06:49:24.342350Z","iopub.status.idle":"2022-02-08T06:49:24.359598Z","shell.execute_reply.started":"2022-02-08T06:49:24.342305Z","shell.execute_reply":"2022-02-08T06:49:24.358344Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    for fold in range(CFG.n_fold):\n        if fold in CFG.trn_fold:\n            train_loop(folds,fold)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:49:24.361695Z","iopub.execute_input":"2022-02-08T06:49:24.362341Z","iopub.status.idle":"2022-02-08T06:52:02.157838Z","shell.execute_reply.started":"2022-02-08T06:49:24.362295Z","shell.execute_reply":"2022-02-08T06:52:02.155497Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}