{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"생육 기간 예측 경진대회.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cpjDegMbeND3l7UYyF5Lth2zT8D11w0X","authorship_tag":"ABX9TyPuvzgR8n0JxLT5lgNaqklz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["## import library ##\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","from torch import optim\n","from torch import nn\n","\n","from torch.utils.data import Dataset\n","from torch.optim.lr_scheduler import StepLR\n","from torchvision.transforms import ToTensor\n","from torchvision import transforms\n","\n","import random\n","from glob import glob\n","import pandas as pd\n","import numpy as np\n","from PIL import Image"],"metadata":{"id":"tg2hPfIOxpZL","executionInfo":{"status":"ok","timestamp":1644221932765,"user_tz":-540,"elapsed":6016,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install timm\n","import timm"],"metadata":{"id":"VQ82gsW1OkuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed): # seed 고정\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","seed_everything(2022)"],"metadata":{"id":"ur5umPTrQXzy","executionInfo":{"status":"ok","timestamp":1644221937312,"user_tz":-540,"elapsed":26,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["## Load data & Preprocess data ##\n","def extract_day(file_name):\n","    day = int(file_name.split('.')[-2][-2:])\n","    return day\n","\n","\n","def make_day_array(image_pathes):\n","    day_array = np.array([extract_day(file_name) for file_name in image_pathes])\n","    return day_array\n","\n","\n","def make_image_path_array(root_path=None):\n","\n","    if root_path is None:\n","        bc_directories = glob('./BC/*')\n","        lt_directories = glob('./LT/*')\n","    else:\n","        # print(root_path)\n","        bc_directories = glob(root_path + 'BC/*')\n","        # print(bc_directories)\n","        lt_directories = glob(root_path + 'LT/*')\n","\n","    bc_image_path = []\n","    for bc_path in bc_directories:\n","        images = glob(bc_path + '/*.png')\n","        bc_image_path.extend(images)\n","\n","    lt_image_path = []\n","    for lt_path in lt_directories:\n","        images = glob(lt_path + '/*.png')\n","        lt_image_path.extend(images)\n","\n","    return bc_image_path, lt_image_path\n","\n","\n","def make_dataframe(root_path=None):\n","    bc_image_path, lt_image_path = make_image_path_array(root_path)\n","    bc_day_array = make_day_array(bc_image_path)\n","    lt_day_array = make_day_array(lt_image_path)\n","\n","    bc_df = pd.DataFrame({'file_name': bc_image_path,\n","                          'day': bc_day_array})\n","    bc_df['species'] = 'bc'\n","\n","    lt_df = pd.DataFrame({'file_name': lt_image_path,\n","                          'day': lt_day_array})\n","    lt_df['species'] = 'lt'\n","\n","    total_data_frame = pd.concat([bc_df, lt_df]).reset_index(drop=True)\n","\n","    return total_data_frame\n","\n","\n","def make_combination(length, species, data_frame):\n","    before_file_path = []\n","    after_file_path = []\n","    time_delta = []\n","\n","    for i in range(length):\n","        sample = data_frame[data_frame['species'] == species].sample(2)\n","        after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n","        before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n","\n","        before_file_path.append(before.iloc[0]['file_name'])\n","        after_file_path.append(after.iloc[0]['file_name'])\n","        delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n","        time_delta.append(delta)\n","\n","    combination_df = pd.DataFrame({\n","        'before_file_path': before_file_path,\n","        'after_file_path': after_file_path,\n","        'time_delta': time_delta,\n","    })\n","\n","    combination_df['species'] = species\n","\n","    return combination_df"],"metadata":{"id":"9inD9FBIEOX3","executionInfo":{"status":"ok","timestamp":1644221937313,"user_tz":-540,"elapsed":24,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## Dataset ##\n","class KistDataset(Dataset):\n","    def __init__(self, combination_df, is_test= None, is_valid = None, is_train = None):\n","        self.combination_df = combination_df\n","        self.transform = transforms.Compose([\n","            # transforms.Resize(224),\n","            transforms.FiveCrop(96),\n","            transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n","            # transforms.ToTensor()\n","        ])\n","        self.transform_test = transforms.Compose([\n","            # transforms.Resize(224),\n","            transforms.FiveCrop(96),\n","            transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n","            # transforms.ToTensor()\n","        ])\n","        self.is_test = is_test\n","        self.is_valid = is_valid\n","        self.is_train = is_train\n","\n","    def __getitem__(self, idx):        \n","        before_image = Image.open(self.combination_df.iloc[idx]['before_file_path'])\n","        after_image = Image.open(self.combination_df.iloc[idx]['after_file_path'])\n","        \n","        if self.is_test:\n","          before_image = self.transform_test(before_image)\n","          after_image = self.transform_test(after_image)\n","          return before_image, after_image\n","        \n","        if self.is_valid:\n","          before_image = self.transform_test(before_image)\n","          after_image = self.transform_test(after_image)\n","        \n","        if self.is_train:\n","          before_image = self.transform(before_image)\n","          after_image = self.transform(after_image)\n","            \n","        time_delta = self.combination_df.iloc[idx]['time_delta']\n","        return before_image, after_image, time_delta\n","\n","    def __len__(self):\n","        return len(self.combination_df)"],"metadata":{"id":"mVNJ7AsYPaRL","executionInfo":{"status":"ok","timestamp":1644221937313,"user_tz":-540,"elapsed":22,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## Model ##\n","class CompareCNN(nn.Module):\n","\n","    def __init__(self):\n","        super(CompareCNN, self).__init__()\n","        self.swin = timm.create_model('tf_efficientnet_b7', pretrained=True)\n","        self.fc_layer = nn.Linear(1000, 1)\n","        \n","    def forward(self, input):\n","        x = self.swin(input)\n","        output = self.fc_layer(x)\n","        return output\n","\n","\n","class CompareNet(nn.Module):\n","\n","    def __init__(self):\n","        super(CompareNet, self).__init__()\n","        self.before_net = CompareCNN()\n","        self.after_net = CompareCNN()\n","\n","    def forward(self, before_input, after_input):\n","        before = self.before_net(before_input)\n","        after = self.after_net(after_input)\n","        delta = before - after\n","        return delta"],"metadata":{"id":"S5bfOAx0Eywc","executionInfo":{"status":"ok","timestamp":1644221937314,"user_tz":-540,"elapsed":22,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["## Training ##\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","lr = 1e-3\n","epochs = 12\n","batch_size = 32\n","valid_batch_size = 50\n","\n","model = CompareNet().to(device)\n","\n","total_dataframe = make_dataframe(root_path = \"/content/drive/MyDrive/seculayer/plant/train_dataset/\")\n","\n","bt_combination = make_combination(6000, 'bc', total_dataframe)\n","lt_combination = make_combination(6000, 'lt', total_dataframe)\n","\n","bt_train = bt_combination.iloc[:5500]\n","bt_valid = bt_combination.iloc[5500:]\n","\n","lt_train = lt_combination.iloc[:5500]\n","lt_valid = lt_combination.iloc[5500:]\n","\n","train_set = pd.concat([bt_train, lt_train])\n","valid_set = pd.concat([bt_valid, lt_valid])\n","\n","train_dataset = KistDataset(train_set, is_train = True)\n","valid_dataset = KistDataset(valid_set, is_valid = True)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","train_data_loader = DataLoader(train_dataset,\n","                               batch_size=batch_size,\n","                               shuffle=True)\n","\n","valid_data_loader = DataLoader(valid_dataset,\n","                               batch_size=valid_batch_size)\n","\n","best_loss = np.inf\n","\n","for epoch in tqdm(range(epochs)):\n","    for step, (before_image, after_image, time_delta) in tqdm(enumerate(train_data_loader)):\n","        \n","        bs, ncrops, c, h, w = before_image.size()\n","        before_image, _, _, _, _ = torch.chunk(before_image, ncrops, dim=1)\n","        before_image = before_image.squeeze()\n","        \n","        after_image, _, _, _, _ = torch.chunk(after_image, ncrops, dim=1)\n","        after_image = after_image.squeeze()\n","\n","        before_image = before_image.to(device)\n","        after_image = after_image.to(device)\n","        time_delta = time_delta.to(device)\n","\n","        optimizer.zero_grad()\n","        logit = model(before_image, after_image)\n","\n","        train_loss = (torch.sum(torch.abs(logit.squeeze(1).float() - time_delta.float())) / torch.LongTensor([batch_size]).squeeze(0).to(device))\n","        train_loss.backward()\n","        optimizer.step()\n","\n","        if step % 100 == 0:\n","          print('Epoch: %d \\t Step: %d \\tTraining Loss: %.6f' %(epoch +1 , step + 1, train_loss.detach().cpu().numpy()))\n","    \n","    scheduler.step()\n","    valid_losses = []\n","    with torch.no_grad():\n","        for valid_before, valid_after, time_delta in tqdm(valid_data_loader):\n","            bs, ncrops, c, h, w = valid_before.size()\n","            valid_before, _, _, _, _ = torch.chunk(valid_before, ncrops, dim=1)\n","            valid_before = valid_before.squeeze()\n","            \n","            valid_after, _, _, _, _ = torch.chunk(valid_after, ncrops, dim=1)\n","            valid_after = valid_after.squeeze()\n","\n","\n","            valid_before = valid_before.to(device)\n","            valid_after = valid_after.to(device)\n","            valid_time_delta = time_delta.to(device)\n","\n","\n","            logit = model(valid_before, valid_after)\n","            valid_loss = (torch.sum(torch.abs(logit.squeeze(1).float() - valid_time_delta.float())) /\n","                          torch.LongTensor([valid_batch_size]).squeeze(0).to(device))\n","            valid_losses.append(valid_loss.detach().cpu())\n","\n","    \n","    loss = sum(valid_losses)/len(valid_losses)\n","    \n","    print(f'VALIDATION_LOSS MAE : {loss}')\n","    if best_loss > loss :\n","      best_loss = loss\n","      torch.save (model.state_dict(), '/content/drive/MyDrive/seculayer/plant/model.pt')\n"],"metadata":{"id":"PFBiT-piE4b7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## inference ##\n","test_set = pd.read_csv('/content/drive/MyDrive/seculayer/plant/test_dataset/test_data.csv')\n","test_set['l_root'] = test_set['before_file_path'].map(lambda x: '/content/drive/MyDrive/seculayer/plant/test_dataset/' + x.split('_')[1] + '/' + x.split('_')[2])\n","test_set['r_root'] = test_set['after_file_path'].map(lambda x: '/content/drive/MyDrive/seculayer/plant/test_dataset/' + x.split('_')[1] + '/' + x.split('_')[2])\n","test_set['before_file_path'] = test_set['l_root'] + '/' + test_set['before_file_path'] + '.png'\n","test_set['after_file_path'] = test_set['r_root'] + '/' + test_set['after_file_path'] + '.png'\n","\n","test_dataset = KistDataset(test_set, is_test=True)\n","\n","test_data_loader = DataLoader(test_dataset,\n","                               batch_size=64)\n","\n","test_value = []\n","with torch.no_grad():\n","    for test_before, test_after in tqdm(test_data_loader):\n","        bs, ncrops, c, h, w = test_before.size()\n","        test_before, _, _, _, _ = torch.chunk(test_before, ncrops, dim=1)\n","        test_before = test_before.squeeze()\n","        \n","        test_after, _, _, _, _ = torch.chunk(test_after, ncrops, dim=1)\n","        test_after = test_after.squeeze()\n","\n","        test_before = test_before.to(device)\n","        test_after = test_after.to(device)\n","        logit = model(test_before, test_after)\n","        value = logit.squeeze(1).detach().cpu().float()\n","        \n","        test_value.extend(value)"],"metadata":{"id":"t8mo9tm5FAxL","executionInfo":{"status":"aborted","timestamp":1644222048026,"user_tz":-540,"elapsed":393,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Make Submission File ##\n","submission = pd.read_csv('/content/drive/MyDrive/seculayer/plant/sample_submission.csv')\n","\n","predict = torch.FloatTensor(test_value)\n","temp_predict = predict.numpy()\n","temp_predict[np.where(temp_predict<1)] = 1\n","\n","submission['time_delta'] = temp_predict\n","submission.to_csv('/content/drive/MyDrive/seculayer/plant/submission.csv', index=False)"],"metadata":{"id":"fudUvkQHUMxz","executionInfo":{"status":"aborted","timestamp":1644222048027,"user_tz":-540,"elapsed":393,"user":{"displayName":"노민주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15712257823924386223"}}},"execution_count":null,"outputs":[]}]}
